{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\nprint(train.count())\n\ndef clean_data(data):\n    data.Age = data.Age.fillna(data.Age.dropna().median())\n    \n    data.loc[data.Sex == \"male\", \"Sex\"] = 0\n    data.loc[data.Sex == \"female\", \"Sex\"] = 1\n    \n    data.Embarked = data.Embarked.fillna(\"S\")\n    data.loc[data.Embarked == \"S\", \"Embarked\"] = 0\n    data.loc[data.Embarked == \"Q\", \"Embarked\"] = 1\n    data.loc[data.Embarked == \"C\", \"Embarked\"] = 2\n    \nclean_data(train)","execution_count":2,"outputs":[{"output_type":"stream","text":"PassengerId    891\nSurvived       891\nPclass         891\nName           891\nSex            891\nAge            714\nSibSp          891\nParch          891\nTicket         891\nFare           891\nCabin          204\nEmbarked       889\ndtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_array = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n\nfeatures = np.asarray(train[features_array].values).astype(np.float32)\ntarget = np.asarray(train.Survived.values).astype(np.float32)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim = features.shape[1], activation = \"relu\"))\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(Dense(1, activation = \"sigmoid\"))\nmodel.compile(loss = \"binary_crossentropy\", optimizer = \"adam\")\n\nmodel.fit(features, target, epochs = 600, batch_size = 1, verbose = 1)\n\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nclean_data(test)\n\narr = model.predict(np.asarray(test[features_array]).astype(np.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = []\nfor x in arr:\n    if x[0] > 0.5:\n        test_predictions.append(1)\n    else:\n        test_predictions.append(0)\n\n        \nsubmission = pd.DataFrame({\n    'PassengerId': np.arange(start=892, stop=892+418, step=1),\n    'Survived': test_predictions\n})\n\nsubmission.to_csv('submission-manual-cleansing.csv', index=False)","execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'arr' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-be2929900fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtest_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'arr' is not defined"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
